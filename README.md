# BERT-large-cased Entity Tagging

# Run

`python run.py --gpu {gpu_id} --batch-size 8 --train-epoch {number_of_training_epoch}`

# Performance

After running one epoch, you should have `{'precision': 0.657904833108713, 'recall': 0.69016119378341, 'f1': 0.6736471002996651}`

# Qiusi's Result

Baseline model: three epoch, {'precision': 0.6659999207826672, 'recall': 0.6940826814720027, 'f1': 0.6797513770276417}
